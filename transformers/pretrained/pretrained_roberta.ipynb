{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f56a76d9",
   "metadata": {},
   "source": [
    "# Pretrained serving with Transformers ðŸ¤ BentoML\n",
    "\n",
    "In this Jupyter notebook file, we will use a pretrained version of [distilroberta-base](https://huggingface.co/distilroberta-base) for emotion detection from text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2eb746",
   "metadata": {},
   "source": [
    "## Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75735630",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff82c1e",
   "metadata": {},
   "source": [
    "## Import pretrained model from HuggingFace to BentoML modelstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a756b0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml\n",
    "import transformers\n",
    "\n",
    "TASKS = \"text-classification\"\n",
    "BENTOML_MODEL_NAME = \"roberta_text_classification\"\n",
    "MODEL = \"j-hartmann/emotion-english-distilroberta-base\"\n",
    "\n",
    "classifier = transformers.pipeline(TASKS, model=MODEL, return_all_scores=True)  # type: ignore\n",
    "tag = bentoml.transformers.save(BENTOML_MODEL_NAME, classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e201d1",
   "metadata": {},
   "source": [
    "This will create a BentoML Model format with tag `roberta_text_classification`.\n",
    "One can retrieve this model with:\n",
    "```bash\n",
    "bentoml models list\n",
    "```\n",
    "\n",
    "Verify this model in an IPython shell:\n",
    "```python\n",
    "import bentoml\n",
    "\n",
    "runner = bentoml.transformers.load_runner(\"roberta_text_classification\",\n",
    "                                          tasks='text-classification',\n",
    "                                          return_all_scores=True)\n",
    "\n",
    "runner.run_batch([\"Hello World\", \"I love you\", \"I hate you\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8758ae65",
   "metadata": {},
   "source": [
    "## Create a BentoML service\n",
    "NOTE: using `%%writefile` here because `bentoml.Service` instance must be created in a separate .py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4693f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile service.py\n",
    "import re\n",
    "import typing as t\n",
    "import asyncio\n",
    "import unicodedata\n",
    "\n",
    "import bentoml\n",
    "from bentoml.io import JSON\n",
    "from bentoml.io import Text\n",
    "\n",
    "\n",
    "MODEL_NAME = \"roberta_text_classification\"\n",
    "TASKS = \"text-classification\"\n",
    "\n",
    "clf_runner = bentoml.transformers.load_runner(MODEL_NAME, tasks=TASKS)\n",
    "\n",
    "all_runner = bentoml.transformers.load_runner(\n",
    "    MODEL_NAME, name=\"all_score_runner\", tasks=TASKS, return_all_scores=True\n",
    ")\n",
    "\n",
    "svc = bentoml.Service(name=\"pretrained_clf\", runners=[clf_runner, all_runner])\n",
    "\n",
    "\n",
    "def normalize(s: str) -> str:\n",
    "    s = \"\".join(\n",
    "        c\n",
    "        for c in unicodedata.normalize(\"NFD\", s.lower().strip())\n",
    "        if unicodedata.category(c) != \"Mn\"\n",
    "    )\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def preprocess(sentence: t.Dict[str, t.List[str]]) -> t.Dict[str, t.List[str]]:\n",
    "    assert 'text' in sentence, \"Given JSON does not contain `text` field\"\n",
    "    if not isinstance(sentence['text'], list):\n",
    "        sentence['text'] = [sentence['text']]\n",
    "    return {k: [normalize(s) for s in v] for k, v in sentence.items()}\n",
    "\n",
    "\n",
    "def convert_result(res) -> t.Dict[str, t.Any]:\n",
    "    if isinstance(res, list):\n",
    "        return {l[\"label\"]: l[\"score\"] for l in res}\n",
    "    return {res[\"label\"]: res[\"score\"]}\n",
    "\n",
    "\n",
    "def postprocess(\n",
    "    inputs: t.Dict[str, t.List[str]], outputs: t.List[t.Dict[str, t.Any]]\n",
    ") -> t.Dict[int, t.Dict[str, t.Union[str, float]]]:\n",
    "    return {\n",
    "        i: {\"input\": sent, **convert_result(pred)}\n",
    "        for i, (sent, pred) in enumerate(zip(inputs[\"text\"], outputs))\n",
    "    }\n",
    "\n",
    "\n",
    "@svc.api(input=Text(), output=JSON())\n",
    "async def sentiment(sentence: str) -> t.Dict[str, t.Any]:\n",
    "    res = await clf_runner.async_run(sentence)\n",
    "    return {\"input\": sentence, \"label\": res['label']}\n",
    "\n",
    "\n",
    "@svc.api(input=JSON(), output=JSON())\n",
    "async def batch_sentiment(sentences: t.Dict[str, t.List[str]]) -> t.Dict[int, t.Dict[str, t.Union[str, float]]]:\n",
    "    processed = preprocess(sentences)\n",
    "    outputs = await asyncio.gather(*[clf_runner.async_run(s) for s in processed[\"text\"]])\n",
    "    return postprocess(processed, outputs)  # type: ignore\n",
    "\n",
    "\n",
    "@svc.api(input=JSON(), output=JSON())\n",
    "async def batch_all_scores(sentences: t.Dict[str, t.List[str]]) -> t.Dict[int, t.Dict[str, t.Union[str, float]]]:\n",
    "    processed = preprocess(sentences)\n",
    "    outputs = await asyncio.gather(*[all_runner.async_run(s) for s in processed[\"text\"]])\n",
    "    return postprocess(processed, outputs)  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133e2f7f",
   "metadata": {},
   "source": [
    "\n",
    "We defined two separate endpoints `/batch_sentiment` and `batch_all_scores` which creates an inference graph to make use of BentoML's dynamic batching, which both\n",
    "returns a list of predicted emotions from given sentence. \n",
    "\n",
    "We also create `/sentiment` endpoints which accept a single sentence as input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2cc61f",
   "metadata": {},
   "source": [
    "\n",
    "Start a service with reload enabled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4b6394",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml serve service:svc --reload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0883da2",
   "metadata": {},
   "source": [
    "With the `--reload` flag, the API server will automatically restart when the source file `service.py` is being updated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bceace0",
   "metadata": {},
   "source": [
    "One can then navigate to `127.0.0.1:3000` and interact with Swagger UI.\n",
    "One can also verify the endpoints locally with `curl`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed32044",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -X POST \"http://127.0.0.1:3000/batch_sentiment\" \\\n",
    "    -H \"accept: application/json\" -H \"Content-Type: text/plain\" \\\n",
    "    -d \"[\\\"I love you\\\",\\\"I hope that we will meet one day, but now, our path diverges\\\"]\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253a6457",
   "metadata": {},
   "source": [
    "We can also do a simple local benchmark with [locust](https://locust.io/):\n",
    "```bash\n",
    "locust --headless -u 100 -r 1000 --run-time 2m --host http://127.0.0.1:3000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42948f3",
   "metadata": {},
   "source": [
    "## Build a Bento for deployment\n",
    "\n",
    "A `bentofile.yaml` can be created to create a Bento with `bentoml build` in the current directory:\n",
    "```yaml\n",
    "service: \"service:svc\"\n",
    "description: \"file: ./README.md\"\n",
    "labels:\n",
    "  owner: bentoml-team\n",
    "  stage: demo\n",
    "include:\n",
    "- \"*.py\"\n",
    "exclude:\n",
    "- \"locustfile.py\"\n",
    "- \"tests/\"\n",
    "- \"*.ipynb\"\n",
    "python:\n",
    "  lock_packages: false\n",
    "  packages:\n",
    "    - -f https://download.pytorch.org/whl/cpu/torch_stable.html\n",
    "    - torch==1.10.2+cpu\n",
    "    - git+https://github.com/huggingface/transformers\n",
    "    - datasets\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5c718d",
   "metadata": {},
   "source": [
    "Build a bento with `bentoml build`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60255359",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml build"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bce58f",
   "metadata": {},
   "source": [
    "This Bento now can be served with `--production`:\n",
    "```bash\n",
    "bentoml serve pretrained_clf:latest --production\n",
    "```\n",
    "\n",
    "## Containerize a Bento\n",
    "\n",
    "Make sure Docker and daemon is running, then `bentoml containerize` will build\n",
    "a docker image for the model server aboved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a679d898",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml containerize pretrained_clf:latest\n",
    "# an example docker tag: pretrained_clf:zt4vvsurw63thgxi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68be7f67",
   "metadata": {},
   "source": [
    "Test out the newly built docker image:\n",
    "```bash\n",
    "docker run -p 3000:3000 pretrained_clf:zt4vvsurw63thgxi\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
