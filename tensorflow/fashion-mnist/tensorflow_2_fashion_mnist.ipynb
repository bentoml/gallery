{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jYysdyb-CaWM"
   },
   "source": [
    "# Basic classification: Classify images of clothing\n",
    "A tensorflow serving style service example using BentoML\n",
    "\n",
    "\n",
    "![Impression](https://www.google-analytics.com/collect?v=1&tid=UA-112879361-3&cid=555&t=event&ec=tensorflow&ea=tensorflow_2_fashion_mnist&dt=tensorflow_2_fashion_mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q bentoml tensorflow matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dzLKpmZICaWN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import io\n",
    "\n",
    "# TensorFlow\n",
    "import tensorflow as tf\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7MqDQO0KCaWS"
   },
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(_train_images, train_labels), (_test_images, test_labels) = fashion_mnist.load_data()\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "train_images = _train_images / 255.0\n",
    "test_images = _test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMnist(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(FashionMnist, self).__init__()\n",
    "        self.cnn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "    \n",
    "    @staticmethod\n",
    "    def image_bytes2tensor(inputs):\n",
    "        with tf.device(\"cpu:0\"):  # map_fn has issues on GPU https://github.com/tensorflow/tensorflow/issues/28007\n",
    "            inputs = tf.map_fn(lambda i: tf.io.decode_png(i, channels=1), inputs, dtype=tf.uint8)\n",
    "        inputs = tf.cast(inputs, tf.float32)\n",
    "        inputs = (255.0 - inputs) / 255.0\n",
    "        inputs = tf.reshape(inputs, [-1, 28, 28])\n",
    "        return inputs\n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=(None,), dtype=tf.string)])\n",
    "    def predict_image(self, inputs):\n",
    "        inputs = self.image_bytes2tensor(inputs)\n",
    "        return self(inputs)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.cnn(inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the image preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ankle boot\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAPaElEQVR4nO3dX4yV9Z3H8c9X/ogCCiMDGYE43WYS16wuNCdkEzeNm7oNciFy0U25aNjEhF5obJNeaLqJ9dJstm32YtNIF1J206VpLEYuzIKSJkYMhKNB/kgUVgc6nZGZAWUG/4DAdy/mcTPFeX6/8TznX/f7fiWTM3O+55nnyzPz4Zw5v+f3/MzdBeD/v5s63QCA9iDsQBCEHQiCsANBEHYgiLnt3NmyZcu8v7+/nbsEQhkcHNT4+LjNVKsUdjNbL+lfJc2R9O/u/mzq8f39/arX61V2CSChVquV1hp+GW9mcyT9m6SHJN0jabOZ3dPo9wPQWlX+Zl8n6bS7v+fuVyT9RtLG5rQFoNmqhH2lpD9M+3qouO9PmNlWM6ubWX1sbKzC7gBUUSXsM70J8KVzb919m7vX3L3W29tbYXcAqqgS9iFJq6d9vUrScLV2ALRKlbAfljRgZl8zs/mSvitpT3PaAtBsDQ+9uftVM3tc0l5NDb3tcPcTTesMQFNVGmd395ckvdSkXgC0EKfLAkEQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4KotGSzmQ1KmpR0TdJVd681oykAzVcp7IW/c/fxJnwfAC3Ey3ggiKphd0n7zOwNM9s60wPMbKuZ1c2sPjY2VnF3ABpVNez3u/s3JD0k6TEz++aND3D3be5ec/dab29vxd0BaFSlsLv7cHE7KukFSeua0RSA5ms47Ga20MwWf/G5pG9LOt6sxgA0V5V341dIesHMvvg+/+Xu/92UrgA0XcNhd/f3JP11E3sB0EIMvQFBEHYgCMIOBEHYgSAIOxBEMybCAB1x7dq1ZP2mm8qfy4oh44Zdvnw5Wb/55puT9VOnTpXWBgYGGuoph2d2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCcfbg3L1SPTWWLUlDQ0OltYMHDya3Xb9+fbK+aNGiZL2VcuPoObt37y6tPfnkk5W+dxme2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMbZkZQbR8957bXXSmuHDh1Kbjs8PJysP/HEEw311Ayjo6PJ+t69e5P1xYsXN7OdWeGZHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCYJw9uNy11+fOTf+KHD58OFk/efJkaW3FihXJbVPXVpekTZs2JetLly4trX322WfJbe+6665k/fz588n6xMREsr5q1apkvRWyz+xmtsPMRs3s+LT7eszsZTM7VdyWH1UAXWE2L+N/JenGS4Y8JWm/uw9I2l98DaCLZcPu7q9KunDD3Rsl7Sw+3ynpkSb3BaDJGn2DboW7j0hScbu87IFmttXM6mZWHxsba3B3AKpq+bvx7r7N3WvuXuvt7W317gCUaDTs58ysT5KK2/QUIAAd12jY90jaUny+RdKLzWkHQKtkx9nNbJekByQtM7MhST+R9Kyk35rZo5LOSvpOK5tE465fv56s58bRL126lKw///zzyXrq+uq5se7Jyclkvco173PbnjhxIlnPjZOnxvgl6erVq8l6K2TD7u6bS0rfanIvAFqI02WBIAg7EARhB4Ig7EAQhB0Igimus5QaqjGz5La54a/c9rl6aprqnDlzktvmPPfcc8l6bprqggULSmtnzpxJbpsbmsvtO3Vccsd04cKFyXpuyeaLFy8m65cvXy6t5YY7G12qmmd2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQgizDh7bkpj1bHulKrLHucu91xlLH3Xrl3J+gcffJCsr127NllPTeX86KOPktv29PQk63fccUeyPj4+XlrLHdNcPSf3+/bJJ5+U1k6fPp3cds2aNQ31xDM7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgQRZpy9yji5lJ6TnpuvnhsHz/VWZRx9x44dyfq7776brK9evTpZzy1dnBpv/vTTT5Pbrly5MlnPXWo6dVxvvfXW5La5ufRVz9tI2bt3b7LOODuAJMIOBEHYgSAIOxAEYQeCIOxAEIQdCOLPapw9N56dkhv3zI2bpuakV52vnjM8PJys7969u7SWG8seGBhI1nPXME9d/1xKj8PPnz8/uW3uZ5aaE56TO3chd1343M88d9351PYHDhxIbtuo7G+pme0ws1EzOz7tvmfM7I9mdqT42NCS7gA0zWyekn4laf0M9//c3dcUHy81ty0AzZYNu7u/KulCG3oB0EJV/th83MyOFi/zl5Y9yMy2mlndzOpjY2MVdgegikbD/gtJX5e0RtKIpJ+WPdDdt7l7zd1rvb29De4OQFUNhd3dz7n7NXe/LumXktY1ty0AzdZQ2M2sb9qXmyQdL3ssgO6QHWc3s12SHpC0zMyGJP1E0gNmtkaSSxqU9P3Z7rDKWuKtHM+uMv84917E4OBgsv7OO+8k6yMjI8l6arz6tttuS26bu3b7xMREsv75558n66lx+NzPM3fcUtekl6QlS5aU1ubNm5fcNtdb7ryMW265JVlP5SC3/vrx4+XPranzKrJhd/fNM9y9PbcdgO7C6bJAEIQdCIKwA0EQdiAIwg4E0fYprlUui3zu3LnS2pkzZ5Lbfvzxx5XqqSGN999/P7ltbirm3LnpH8PixYuT9dTU34sXLya3zU2BzfWW+7elhqBy00ivXLmSrN95553Jeurfnut76dLSM8Al5af+fvjhh8l6agpsbpnsCxfKp6qkhvR4ZgeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBILrqUtKvvPJKsp66pHJuPDg3DTU1Pimlzw+oOk6eG7PNjbumplvmLvWcG0/OXb4713vquOYut5yb6nn77bcn66Ojo8l6Fbnjlpsimzq/IXd+Qe73rbSnhrYC8GeHsANBEHYgCMIOBEHYgSAIOxAEYQeCaOs4+8TEhPbt21da3749fdHau+++u7TW19dXWpOqzQmX0pdrzo3R5y47nOstN+6aGtOdnJxMbpvrLTffPXcJ7tRxzZ0/kLp+gSS9/fbbyXrquOV+Zjm5cwBy8+VTc/lz33v58uWltdQlsnlmB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEg2jrOvnDhQq1bt660fvDgweT2x44dK60dOHCg4b6kanPSe3p6ktvm6rl52blx9tRY+fnz55Pb5paLzo0X55Z0To3Dv/XWW8lt77vvvmS9v78/WU9dHyE3z7/KEt5S/vdp5cqVpbXceRepcycqXTfezFab2e/N7KSZnTCzHxT395jZy2Z2qrhNz+YH0FGzeRl/VdKP3P0vJf2NpMfM7B5JT0na7+4DkvYXXwPoUtmwu/uIu79ZfD4p6aSklZI2StpZPGynpEda1SSA6r7SG3Rm1i9praRDkla4+4g09R+CpBlP2DWzrWZWN7P6+Ph4tW4BNGzWYTezRZJ+J+mH7p5+V2Yad9/m7jV3ry1btqyRHgE0wazCbmbzNBX0X7v77uLuc2bWV9T7JLXuUp4AKssOvdnUGMR2SSfd/WfTSnskbZH0bHH7Yu57zZkzR0uWLCmtP/3007lvUSp3SeNDhw4l67khqNdff720Njg4mNz26NGjyXqu9ypyS2TnhgXvvffeZP3BBx9M1jds2FBaW7BgQXLbqh5++OHS2tmzZ5Pb5l6F5obHcvXU0FxuKeuBgYHSWuqYzmac/X5J35N0zMyOFPf9WFMh/62ZPSrprKTvzOJ7AeiQbNjd/TVJZWcYfKu57QBoFU6XBYIg7EAQhB0IgrADQRB2IAjLXUq4mWq1mtfr9bbtD4imVqupXq/POHrGMzsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgSRDbuZrTaz35vZSTM7YWY/KO5/xsz+aGZHio/yhbgBdNxs1me/KulH7v6mmS2W9IaZvVzUfu7u/9K69gA0y2zWZx+RNFJ8PmlmJyWtbHVjAJrrK/3Nbmb9ktZKOlTc9biZHTWzHWa2tGSbrWZWN7P62NhYpWYBNG7WYTezRZJ+J+mH7j4h6ReSvi5pjaae+X8603buvs3da+5e6+3tbULLABoxq7Cb2TxNBf3X7r5bktz9nLtfc/frkn4paV3r2gRQ1WzejTdJ2yWddPefTbu/b9rDNkk63vz2ADTLbN6Nv1/S9yQdM7MjxX0/lrTZzNZIckmDkr7fkg4BNMVs3o1/TdJM6z2/1Px2ALQKZ9ABQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCMHdv387MxiSdmXbXMknjbWvgq+nW3rq1L4neGtXM3u5y9xmv/9bWsH9p52Z1d691rIGEbu2tW/uS6K1R7eqNl/FAEIQdCKLTYd/W4f2ndGtv3dqXRG+NaktvHf2bHUD7dPqZHUCbEHYgiI6E3czWm9k7ZnbazJ7qRA9lzGzQzI4Vy1DXO9zLDjMbNbPj0+7rMbOXzexUcTvjGnsd6q0rlvFOLDPe0WPX6eXP2/43u5nNkfSupL+XNCTpsKTN7v52WxspYWaDkmru3vETMMzsm5IuSfoPd/+r4r5/lnTB3Z8t/qNc6u5Pdklvz0i61OllvIvVivqmLzMu6RFJ/6gOHrtEX/+gNhy3Tjyzr5N02t3fc/crkn4jaWMH+uh67v6qpAs33L1R0s7i852a+mVpu5LeuoK7j7j7m8Xnk5K+WGa8o8cu0VdbdCLsKyX9YdrXQ+qu9d5d0j4ze8PMtna6mRmscPcRaeqXR9LyDvdzo+wy3u10wzLjXXPsGln+vKpOhH2mpaS6afzvfnf/hqSHJD1WvFzF7MxqGe92mWGZ8a7Q6PLnVXUi7EOSVk/7epWk4Q70MSN3Hy5uRyW9oO5bivrcFyvoFrejHe7n/3TTMt4zLTOuLjh2nVz+vBNhPyxpwMy+ZmbzJX1X0p4O9PElZraweONEZrZQ0rfVfUtR75G0pfh8i6QXO9jLn+iWZbzLlhlXh49dx5c/d/e2f0jaoKl35P9H0j91ooeSvv5C0lvFx4lO9yZpl6Ze1n2uqVdEj0q6Q9J+SaeK254u6u0/JR2TdFRTwerrUG9/q6k/DY9KOlJ8bOj0sUv01ZbjxumyQBCcQQcEQdiBIAg7EARhB4Ig7EAQhB0IgrADQfwv0EcgdA4aVhQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pick up a test image\n",
    "d_test_img = _test_images[0]\n",
    "print(class_names[test_labels[0]])\n",
    "\n",
    "plt.imshow(255.0 - d_test_img, cmap='gray')\n",
    "plt.imsave(\"test.png\", 255.0 - d_test_img, cmap='gray')\n",
    "\n",
    "# read bytes\n",
    "with open(\"test.png\", \"rb\") as f:\n",
    "    img_bytes = f.read()\n",
    "\n",
    "# verify saved image\n",
    "assert tf.reduce_mean(FashionMnist.image_bytes2tensor(tf.constant([img_bytes])) - d_test_img) < 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ODch-OFCaW4"
   },
   "source": [
    "## Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lhan11blCaW7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.5019 - accuracy: 0.8245\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 3s 51us/sample - loss: 0.3775 - accuracy: 0.8638\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.3397 - accuracy: 0.8765\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.3135 - accuracy: 0.8852\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.2946 - accuracy: 0.8908\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.2792 - accuracy: 0.8968\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 3s 52us/sample - loss: 0.2695 - accuracy: 0.9012\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.2575 - accuracy: 0.9033\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.2478 - accuracy: 0.9072\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.2403 - accuracy: 0.9105\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.2319 - accuracy: 0.9134\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.2239 - accuracy: 0.9163\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.2181 - accuracy: 0.9187\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.2129 - accuracy: 0.9200\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 3s 53us/sample - loss: 0.2053 - accuracy: 0.9235\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.1995 - accuracy: 0.9245\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.1942 - accuracy: 0.9268\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1879 - accuracy: 0.9289\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1849 - accuracy: 0.9305\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.1788 - accuracy: 0.9328\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.1779 - accuracy: 0.9330\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.1715 - accuracy: 0.9363\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1661 - accuracy: 0.9368\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1605 - accuracy: 0.9390\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1584 - accuracy: 0.9406\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1543 - accuracy: 0.9420\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1522 - accuracy: 0.9423\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1486 - accuracy: 0.9437\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1448 - accuracy: 0.9452\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.1421 - accuracy: 0.9477\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1394 - accuracy: 0.9478\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1369 - accuracy: 0.9478\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1323 - accuracy: 0.9506\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1299 - accuracy: 0.9512\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.1285 - accuracy: 0.9511\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1252 - accuracy: 0.9530\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.1255 - accuracy: 0.9526\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1196 - accuracy: 0.9546\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 3s 57us/sample - loss: 0.1182 - accuracy: 0.9548\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.1157 - accuracy: 0.9557\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.1153 - accuracy: 0.9570\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1089 - accuracy: 0.9596\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1098 - accuracy: 0.9586\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 3s 54us/sample - loss: 0.1087 - accuracy: 0.9590\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1037 - accuracy: 0.9609\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.1059 - accuracy: 0.9600\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.1024 - accuracy: 0.9623\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 3s 56us/sample - loss: 0.1004 - accuracy: 0.9622\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.1000 - accuracy: 0.9624\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 3s 55us/sample - loss: 0.0957 - accuracy: 0.9641\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f477003d9b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = FashionMnist()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model inference test run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ankle boot']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model.predict_image(tf.constant([img_bytes]))\n",
    "klass = tf.argmax(predict, axis=1)\n",
    "[class_names[c] for c in klass]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YFc2HbEVCaXd"
   },
   "source": [
    "And the model predicts a label as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create BentoService class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tensorflow_fashion_mnist.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tensorflow_fashion_mnist.py\n",
    "\n",
    "import bentoml\n",
    "import tensorflow as tf\n",
    "\n",
    "from bentoml.artifact import TensorflowSavedModelArtifact\n",
    "from bentoml.adapters import TfTensorInput\n",
    "\n",
    "\n",
    "FASHION_MNIST_CLASSES = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "\n",
    "@bentoml.env(pip_dependencies=['tensorflow', 'numpy', 'pillow'])\n",
    "@bentoml.artifacts([TensorflowSavedModelArtifact('model')])\n",
    "class FashionMnistTensorflow(bentoml.BentoService):\n",
    "\n",
    "    @bentoml.api(input=TfTensorInput(), batch=True)\n",
    "    def predict(self, inputs):\n",
    "        outputs = self.artifacts.model.predict_image(inputs)\n",
    "        output_classes = tf.math.argmax(outputs, axis=1)\n",
    "        return [FASHION_MNIST_CLASSES[c] for c in output_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-07-28 15:36:46,482] WARNING - Using BentoML installed in `editable` model, the local BentoML repository including all code changes will be packaged together with saved bundle created, under the './bundled_pip_dependencies' directory of the saved bundle.\n",
      "WARNING:tensorflow:From /opt/anaconda3/envs/bentoml-dev-py36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /tmp/bentoml-temp-8dcup0pe/FashionMnistTensorflow/artifacts/model_saved_model/assets\n",
      "[2020-07-28 15:36:58,212] INFO - Detect BentoML installed in development model, copying local BentoML module file to target saved bundle path\n",
      "running sdist\n",
      "running egg_info\n",
      "writing BentoML.egg-info/PKG-INFO\n",
      "writing dependency_links to BentoML.egg-info/dependency_links.txt\n",
      "writing entry points to BentoML.egg-info/entry_points.txt\n",
      "writing requirements to BentoML.egg-info/requires.txt\n",
      "writing top-level names to BentoML.egg-info/top_level.txt\n",
      "reading manifest file 'BentoML.egg-info/SOURCES.txt'\n",
      "reading manifest template 'MANIFEST.in'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "warning: no previously-included files matching '*.pyo' found anywhere in distribution\n",
      "warning: no previously-included files matching '.git' found anywhere in distribution\n",
      "warning: no previously-included files matching '.ipynb_checkpoints' found anywhere in distribution\n",
      "warning: no previously-included files matching '__pycache__' found anywhere in distribution\n",
      "warning: no directories found matching 'bentoml/server/static'\n",
      "warning: no directories found matching 'bentoml/yatai/web/dist'\n",
      "no previously-included directories found matching 'e2e_tests'\n",
      "no previously-included directories found matching 'tests'\n",
      "no previously-included directories found matching 'benchmark'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing manifest file 'BentoML.egg-info/SOURCES.txt'\n",
      "running check\n",
      "creating BentoML-0.8.3+42.gb8d36b6\n",
      "creating BentoML-0.8.3+42.gb8d36b6/BentoML.egg-info\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/clipper\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/configuration\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/configuration/__pycache__\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/handlers\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/marshal\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/saved_bundle\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/server\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/client\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/aws_lambda\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/azure_functions\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/sagemaker\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations/__pycache__\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations/versions\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations/versions/__pycache__\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/proto\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/repository\n",
      "creating BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/validator\n",
      "copying files to BentoML-0.8.3+42.gb8d36b6...\n",
      "copying LICENSE -> BentoML-0.8.3+42.gb8d36b6\n",
      "copying MANIFEST.in -> BentoML-0.8.3+42.gb8d36b6\n",
      "copying README.md -> BentoML-0.8.3+42.gb8d36b6\n",
      "copying pyproject.toml -> BentoML-0.8.3+42.gb8d36b6\n",
      "copying setup.cfg -> BentoML-0.8.3+42.gb8d36b6\n",
      "copying setup.py -> BentoML-0.8.3+42.gb8d36b6\n",
      "copying versioneer.py -> BentoML-0.8.3+42.gb8d36b6\n",
      "copying BentoML.egg-info/PKG-INFO -> BentoML-0.8.3+42.gb8d36b6/BentoML.egg-info\n",
      "copying BentoML.egg-info/SOURCES.txt -> BentoML-0.8.3+42.gb8d36b6/BentoML.egg-info\n",
      "copying BentoML.egg-info/dependency_links.txt -> BentoML-0.8.3+42.gb8d36b6/BentoML.egg-info\n",
      "copying BentoML.egg-info/entry_points.txt -> BentoML-0.8.3+42.gb8d36b6/BentoML.egg-info\n",
      "copying BentoML.egg-info/requires.txt -> BentoML-0.8.3+42.gb8d36b6/BentoML.egg-info\n",
      "copying BentoML.egg-info/top_level.txt -> BentoML-0.8.3+42.gb8d36b6/BentoML.egg-info\n",
      "copying bentoml/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml\n",
      "copying bentoml/_version.py -> BentoML-0.8.3+42.gb8d36b6/bentoml\n",
      "copying bentoml/exceptions.py -> BentoML-0.8.3+42.gb8d36b6/bentoml\n",
      "copying bentoml/service.py -> BentoML-0.8.3+42.gb8d36b6/bentoml\n",
      "copying bentoml/service_env.py -> BentoML-0.8.3+42.gb8d36b6/bentoml\n",
      "copying bentoml/adapters/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/base_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/base_output.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/clipper_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/dataframe_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/dataframe_output.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/default_output.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/fastai_image_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/file_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/image_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/json_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/json_output.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/legacy_image_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/legacy_json_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/multi_image_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/pytorch_tensor_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/tensorflow_tensor_input.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/tensorflow_tensor_output.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/adapters/utils.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/adapters\n",
      "copying bentoml/artifact/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/fastai2_model_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/fastai_model_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/fasttext_model_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/h2o_model_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/json_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/keras_model_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/lightgbm_model_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/onnx_model_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/pickle_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/pytorch_model_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/sklearn_model_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/spacy_model_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/text_file_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/tf_savedmodel_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/artifact/xgboost_model_artifact.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/artifact\n",
      "copying bentoml/cli/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "copying bentoml/cli/aws_lambda.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "copying bentoml/cli/aws_sagemaker.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "copying bentoml/cli/azure_functions.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "copying bentoml/cli/bento_management.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "copying bentoml/cli/bento_service.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "copying bentoml/cli/click_utils.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "copying bentoml/cli/config.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "copying bentoml/cli/deployment.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "copying bentoml/cli/utils.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "copying bentoml/cli/yatai_service.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/cli\n",
      "copying bentoml/clipper/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/clipper\n",
      "copying bentoml/configuration/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/configuration\n",
      "copying bentoml/configuration/configparser.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/configuration\n",
      "copying bentoml/configuration/default_bentoml.cfg -> BentoML-0.8.3+42.gb8d36b6/bentoml/configuration\n",
      "copying bentoml/configuration/__pycache__/__init__.cpython-36.pyc -> BentoML-0.8.3+42.gb8d36b6/bentoml/configuration/__pycache__\n",
      "copying bentoml/configuration/__pycache__/__init__.cpython-37.pyc -> BentoML-0.8.3+42.gb8d36b6/bentoml/configuration/__pycache__\n",
      "copying bentoml/configuration/__pycache__/__init__.cpython-38.pyc -> BentoML-0.8.3+42.gb8d36b6/bentoml/configuration/__pycache__\n",
      "copying bentoml/configuration/__pycache__/configparser.cpython-36.pyc -> BentoML-0.8.3+42.gb8d36b6/bentoml/configuration/__pycache__\n",
      "copying bentoml/configuration/__pycache__/configparser.cpython-37.pyc -> BentoML-0.8.3+42.gb8d36b6/bentoml/configuration/__pycache__\n",
      "copying bentoml/configuration/__pycache__/configparser.cpython-38.pyc -> BentoML-0.8.3+42.gb8d36b6/bentoml/configuration/__pycache__\n",
      "copying bentoml/handlers/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/handlers\n",
      "copying bentoml/marshal/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/marshal\n",
      "copying bentoml/marshal/dispatcher.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/marshal\n",
      "copying bentoml/marshal/marshal.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/marshal\n",
      "copying bentoml/marshal/utils.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/marshal\n",
      "copying bentoml/saved_bundle/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/saved_bundle\n",
      "copying bentoml/saved_bundle/bentoml-init.sh -> BentoML-0.8.3+42.gb8d36b6/bentoml/saved_bundle\n",
      "copying bentoml/saved_bundle/bundler.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/saved_bundle\n",
      "copying bentoml/saved_bundle/config.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/saved_bundle\n",
      "copying bentoml/saved_bundle/docker-entrypoint.sh -> BentoML-0.8.3+42.gb8d36b6/bentoml/saved_bundle\n",
      "copying bentoml/saved_bundle/loader.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/saved_bundle\n",
      "copying bentoml/saved_bundle/pip_pkg.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/saved_bundle\n",
      "copying bentoml/saved_bundle/py_module_utils.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/saved_bundle\n",
      "copying bentoml/saved_bundle/templates.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/saved_bundle\n",
      "copying bentoml/server/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/server\n",
      "copying bentoml/server/api_server.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/server\n",
      "copying bentoml/server/gunicorn_config.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/server\n",
      "copying bentoml/server/gunicorn_server.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/server\n",
      "copying bentoml/server/instruments.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/server\n",
      "copying bentoml/server/marshal_server.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/server\n",
      "copying bentoml/server/open_api.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/server\n",
      "copying bentoml/server/trace.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/server\n",
      "copying bentoml/server/utils.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/server\n",
      "copying bentoml/utils/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/utils/alg.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/utils/benchmark.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/utils/cloudpickle.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/utils/dataframe_util.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/utils/flask_ngrok.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/utils/hybridmethod.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/utils/lazy_loader.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/utils/log.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/utils/s3.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/utils/tempdir.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/utils/usage_stats.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/utils\n",
      "copying bentoml/yatai/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai\n",
      "copying bentoml/yatai/alembic.ini -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai\n",
      "copying bentoml/yatai/db.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai\n",
      "copying bentoml/yatai/deployment_utils.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai\n",
      "copying bentoml/yatai/status.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai\n",
      "copying bentoml/yatai/utils.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai\n",
      "copying bentoml/yatai/yatai_service.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai\n",
      "copying bentoml/yatai/yatai_service_impl.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai\n",
      "copying bentoml/yatai/client/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/client\n",
      "copying bentoml/yatai/client/bento_repository_api.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/client\n",
      "copying bentoml/yatai/client/deployment_api.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/client\n",
      "copying bentoml/yatai/deployment/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment\n",
      "copying bentoml/yatai/deployment/operator.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment\n",
      "copying bentoml/yatai/deployment/store.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment\n",
      "copying bentoml/yatai/deployment/utils.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment\n",
      "copying bentoml/yatai/deployment/aws_lambda/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/aws_lambda\n",
      "copying bentoml/yatai/deployment/aws_lambda/download_extra_resources.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/aws_lambda\n",
      "copying bentoml/yatai/deployment/aws_lambda/lambda_app.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/aws_lambda\n",
      "copying bentoml/yatai/deployment/aws_lambda/operator.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/aws_lambda\n",
      "copying bentoml/yatai/deployment/aws_lambda/utils.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/aws_lambda\n",
      "copying bentoml/yatai/deployment/azure_functions/Dockerfile -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/azure_functions\n",
      "copying bentoml/yatai/deployment/azure_functions/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/azure_functions\n",
      "copying bentoml/yatai/deployment/azure_functions/app_init.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/azure_functions\n",
      "copying bentoml/yatai/deployment/azure_functions/constants.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/azure_functions\n",
      "copying bentoml/yatai/deployment/azure_functions/host.json -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/azure_functions\n",
      "copying bentoml/yatai/deployment/azure_functions/local.settings.json -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/azure_functions\n",
      "copying bentoml/yatai/deployment/azure_functions/operator.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/azure_functions\n",
      "copying bentoml/yatai/deployment/azure_functions/templates.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/azure_functions\n",
      "copying bentoml/yatai/deployment/sagemaker/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/sagemaker\n",
      "copying bentoml/yatai/deployment/sagemaker/model_server.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/sagemaker\n",
      "copying bentoml/yatai/deployment/sagemaker/nginx.conf -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/sagemaker\n",
      "copying bentoml/yatai/deployment/sagemaker/operator.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/sagemaker\n",
      "copying bentoml/yatai/deployment/sagemaker/serve -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/sagemaker\n",
      "copying bentoml/yatai/deployment/sagemaker/wsgi.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/deployment/sagemaker\n",
      "copying bentoml/yatai/migrations/README -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations\n",
      "copying bentoml/yatai/migrations/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations\n",
      "copying bentoml/yatai/migrations/env.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations\n",
      "copying bentoml/yatai/migrations/script.py.mako -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations\n",
      "copying bentoml/yatai/migrations/__pycache__/env.cpython-36.pyc -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations/__pycache__\n",
      "copying bentoml/yatai/migrations/versions/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations/versions\n",
      "copying bentoml/yatai/migrations/versions/a6b00ae45279_add_last_updated_at_for_deployments.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations/versions\n",
      "copying bentoml/yatai/migrations/versions/__pycache__/a6b00ae45279_add_last_updated_at_for_deployments.cpython-36.pyc -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/migrations/versions/__pycache__\n",
      "copying bentoml/yatai/proto/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/proto\n",
      "copying bentoml/yatai/proto/deployment_pb2.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/proto\n",
      "copying bentoml/yatai/proto/repository_pb2.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/proto\n",
      "copying bentoml/yatai/proto/status_pb2.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/proto\n",
      "copying bentoml/yatai/proto/yatai_service_pb2.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/proto\n",
      "copying bentoml/yatai/proto/yatai_service_pb2_grpc.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/proto\n",
      "copying bentoml/yatai/repository/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/repository\n",
      "copying bentoml/yatai/repository/base_repository.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/repository\n",
      "copying bentoml/yatai/repository/local_repository.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/repository\n",
      "copying bentoml/yatai/repository/metadata_store.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/repository\n",
      "copying bentoml/yatai/repository/repository.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/repository\n",
      "copying bentoml/yatai/repository/s3_repository.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/repository\n",
      "copying bentoml/yatai/validator/__init__.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/validator\n",
      "copying bentoml/yatai/validator/deployment_pb_validator.py -> BentoML-0.8.3+42.gb8d36b6/bentoml/yatai/validator\n",
      "Writing BentoML-0.8.3+42.gb8d36b6/setup.cfg\n",
      "UPDATING BentoML-0.8.3+42.gb8d36b6/bentoml/_version.py\n",
      "set BentoML-0.8.3+42.gb8d36b6/bentoml/_version.py to '0.8.3+42.gb8d36b6'\n",
      "Creating tar archive\n",
      "removing 'BentoML-0.8.3+42.gb8d36b6' (and everything under it)\n",
      "[2020-07-28 15:36:59,228] INFO - BentoService bundle 'FashionMnistTensorflow:20200728153646_C57052' saved to: /home/bentoml/bentoml/repository/FashionMnistTensorflow/20200728153646_C57052\n"
     ]
    }
   ],
   "source": [
    "from tensorflow_fashion_mnist import FashionMnistTensorflow\n",
    "\n",
    "bento_svc = FashionMnistTensorflow()\n",
    "bento_svc.pack(\"model\", model)\n",
    "saved_path = bento_svc.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use BentoService with BentoML CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bentoml get <BentoService Name>` list all of BentoService's versions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml get FashionMnistTensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`bentoml get <BentoService name>:<bentoService version>` display detailed information of the specific BentoService version**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-07-28 15:41:15,592] INFO - Getting latest version FashionMnistTensorflow:20200728153646_C57052\n",
      "\u001b[39m{\n",
      "  \"name\": \"FashionMnistTensorflow\",\n",
      "  \"version\": \"20200728153646_C57052\",\n",
      "  \"uri\": {\n",
      "    \"type\": \"LOCAL\",\n",
      "    \"uri\": \"/home/bentoml/bentoml/repository/FashionMnistTensorflow/20200728153646_C57052\"\n",
      "  },\n",
      "  \"bentoServiceMetadata\": {\n",
      "    \"name\": \"FashionMnistTensorflow\",\n",
      "    \"version\": \"20200728153646_C57052\",\n",
      "    \"createdAt\": \"2020-07-28T07:36:59.200032Z\",\n",
      "    \"env\": {\n",
      "      \"condaEnv\": \"name: bentoml-FashionMnistTensorflow\\nchannels:\\n- defaults\\ndependencies:\\n- python=3.6.10\\n- pip\\n\",\n",
      "      \"pipDependencies\": \"tensorflow\\nbentoml==0.8.3\\nnumpy\\npillow\",\n",
      "      \"pythonVersion\": \"3.6.10\",\n",
      "      \"dockerBaseImage\": \"bentoml/model-server:0.8.3\"\n",
      "    },\n",
      "    \"artifacts\": [\n",
      "      {\n",
      "        \"name\": \"model\",\n",
      "        \"artifactType\": \"TensorflowSavedModelArtifact\"\n",
      "      }\n",
      "    ],\n",
      "    \"apis\": [\n",
      "      {\n",
      "        \"name\": \"predict\",\n",
      "        \"inputType\": \"TfTensorInput\",\n",
      "        \"docs\": \"BentoService inference API 'predict', input: 'TfTensorInput', output: 'DefaultOutput'\",\n",
      "        \"inputConfig\": {\n",
      "          \"method\": \"predict\",\n",
      "          \"is_batch_input\": true\n",
      "        },\n",
      "        \"outputConfig\": {\n",
      "          \"cors\": \"*\"\n",
      "        },\n",
      "        \"outputType\": \"DefaultOutput\",\n",
      "        \"mbMaxLatency\": 10000,\n",
      "        \"mbMaxBatchSize\": 2000\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!bentoml get FashionMnistTensorflow:latest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Serve bentoml REST server locally**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-07-28 15:39:14,893] INFO - Getting latest version FashionMnistTensorflow:20200728153646_C57052\n",
      "[2020-07-28 15:39:14,893] INFO - Starting BentoML API server in development mode..\n",
      "[2020-07-28 15:39:16,013] WARNING - Using BentoML installed in `editable` model, the local BentoML repository including all code changes will be packaged together with saved bundle created, under the './bundled_pip_dependencies' directory of the saved bundle.\n",
      "[2020-07-28 15:39:16,036] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.8.3, but loading from BentoML version 0.8.3+42.gb8d36b6\n",
      "2020-07-28 15:39:17.628512: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-07-28 15:39:17.643972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-28 15:39:17.644615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1060 computeCapability: 6.1\n",
      "coreClock: 1.6705GHz coreCount: 10 deviceMemorySize: 5.93GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2020-07-28 15:39:17.644822: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-07-28 15:39:17.646534: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-07-28 15:39:17.648390: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-07-28 15:39:17.648745: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-07-28 15:39:17.650656: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-07-28 15:39:17.651735: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-07-28 15:39:17.654958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-07-28 15:39:17.655092: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-28 15:39:17.655520: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-28 15:39:17.655816: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
      "2020-07-28 15:39:17.656046: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-07-28 15:39:17.795174: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-28 15:39:17.795603: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d4fe6ec2f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-07-28 15:39:17.795621: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1060, Compute Capability 6.1\n",
      "2020-07-28 15:39:17.795770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-28 15:39:17.796095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1060 computeCapability: 6.1\n",
      "coreClock: 1.6705GHz coreCount: 10 deviceMemorySize: 5.93GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2020-07-28 15:39:17.796129: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-07-28 15:39:17.796146: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-07-28 15:39:17.796159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-07-28 15:39:17.796172: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-07-28 15:39:17.796186: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-07-28 15:39:17.796236: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-07-28 15:39:17.796262: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-07-28 15:39:17.796343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-28 15:39:17.796708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-28 15:39:17.797002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
      "2020-07-28 15:39:17.797030: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-07-28 15:39:17.797505: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-07-28 15:39:17.797517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
      "2020-07-28 15:39:17.797523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
      "2020-07-28 15:39:17.797606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-28 15:39:17.797948: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-28 15:39:17.798261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5065 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2020-07-28 15:39:17.821394: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2699905000 Hz\n",
      "2020-07-28 15:39:17.821762: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d4fe719900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-07-28 15:39:17.821807: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      " * Serving Flask app \"FashionMnistTensorflow\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n",
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!bentoml serve FashionMnistTensorflow:latest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query REST API with python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: {\"instances\": [{\"b64\": \"iVBORw0KGgoAAAANSUhEUgAAAB ... ufkz8DPG//sD/AX8I8DvdgnOxdB4B1wAAAAASUVORK5CYII=\"}]}\n",
      "<Response [200]>\n",
      "[\"Ankle boot\"]\n"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "import json\n",
    "import requests\n",
    "\n",
    "with open(\"test.png\", \"rb\") as f:\n",
    "    img_bytes = f.read()\n",
    "img_b64 = base64.b64encode(img_bytes).decode()\n",
    "\n",
    "\n",
    "headers = {\"content-type\": \"application/json\"}\n",
    "data = json.dumps(\n",
    "       {\"instances\": [{\"b64\": img_b64}]}\n",
    ")\n",
    "print('Data: {} ... {}'.format(data[:50], data[len(data)-52:]))\n",
    "\n",
    "json_response = requests.post(f'http://localhost:5000/predict', data=data, headers=headers)\n",
    "print(json_response)\n",
    "print(json_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use BentoService as PyPI package\n",
    "\n",
    "`pip install $SAVED_PATH` also installs a CLI tool for accessing the BentoML service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install -q {saved_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: FashionMnistTensorflow [OPTIONS] COMMAND [ARGS]...\n",
      "\n",
      "  BentoML CLI tool\n",
      "\n",
      "Options:\n",
      "  --version  Show the version and exit.\n",
      "  --help     Show this message and exit.\n",
      "\n",
      "Commands:\n",
      "  containerize        Containerizes given Bento into a ready-to-use Docker\n",
      "                      image\n",
      "\n",
      "  info                List APIs\n",
      "  install-completion  Install shell command completion\n",
      "  open-api-spec       Display OpenAPI/Swagger JSON specs\n",
      "  run                 Run API function\n",
      "  serve               Start local dev API server\n",
      "  serve-gunicorn      Start production API server\n"
     ]
    }
   ],
   "source": [
    "!FashionMnistTensorflow --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run 'predict' api with json data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-28 15:45:44.309676: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-07-28 15:45:44.324141: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-28 15:45:44.324506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1060 computeCapability: 6.1\n",
      "coreClock: 1.6705GHz coreCount: 10 deviceMemorySize: 5.93GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2020-07-28 15:45:44.324699: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-07-28 15:45:44.326113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-07-28 15:45:44.327389: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-07-28 15:45:44.327618: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-07-28 15:45:44.329060: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-07-28 15:45:44.329947: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-07-28 15:45:44.333107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-07-28 15:45:44.333293: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-28 15:45:44.333693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-28 15:45:44.334018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
      "2020-07-28 15:45:44.334257: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "2020-07-28 15:45:44.357433: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2699905000 Hz\n",
      "2020-07-28 15:45:44.357821: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5594561dee60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-07-28 15:45:44.357859: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-07-28 15:45:44.358360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-28 15:45:44.358965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \n",
      "pciBusID: 0000:01:00.0 name: GeForce GTX 1060 computeCapability: 6.1\n",
      "coreClock: 1.6705GHz coreCount: 10 deviceMemorySize: 5.93GiB deviceMemoryBandwidth: 178.99GiB/s\n",
      "2020-07-28 15:45:44.359027: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-07-28 15:45:44.359055: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "2020-07-28 15:45:44.359079: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
      "2020-07-28 15:45:44.359107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
      "2020-07-28 15:45:44.359133: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
      "2020-07-28 15:45:44.359158: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
      "2020-07-28 15:45:44.359183: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-07-28 15:45:44.359282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-28 15:45:44.359891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-28 15:45:44.360422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\n",
      "2020-07-28 15:45:44.360476: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "2020-07-28 15:45:44.500133: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-07-28 15:45:44.500167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \n",
      "2020-07-28 15:45:44.500179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \n",
      "2020-07-28 15:45:44.500530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-28 15:45:44.501328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-28 15:45:44.502447: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-07-28 15:45:44.502893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5065 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "2020-07-28 15:45:44.505063: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5594570adff0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2020-07-28 15:45:44.505092: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1060, Compute Capability 6.1\n",
      "2020-07-28 15:45:46.298717: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
      "['Ankle boot']\n"
     ]
    }
   ],
   "source": [
    "!echo '{\\\"instances\\\":[{\\\"b64\\\":\\\"'$(base64 test.png)'\\\"}]}' > test.json\n",
    "!cat test.json | xargs -I {} FashionMnistTensorflow run predict --input={}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build realtime prediction service in docker with BentoService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sha256:dbf669648a388423aedf26c2124c31299c5453fc8a5740ad15bddafe22fda5e5\n"
     ]
    }
   ],
   "source": [
    "!docker build --quiet -t tensorflow2-fashion-mnist {saved_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-07-28 07:51:49,529] INFO - Starting BentoML API server in production mode..\n",
      "[2020-07-28 07:51:49,927] INFO - Running micro batch service on :5000\n",
      "[2020-07-28 07:51:49 +0000] [12] [INFO] Starting gunicorn 20.0.4\n",
      "[2020-07-28 07:51:49 +0000] [1] [INFO] Starting gunicorn 20.0.4\n",
      "[2020-07-28 07:51:49 +0000] [12] [INFO] Listening at: http://0.0.0.0:5000 (12)\n",
      "[2020-07-28 07:51:49 +0000] [12] [INFO] Using worker: aiohttp.worker.GunicornWebWorker\n",
      "[2020-07-28 07:51:49 +0000] [1] [INFO] Listening at: http://0.0.0.0:37381 (1)\n",
      "[2020-07-28 07:51:49 +0000] [1] [INFO] Using worker: sync\n",
      "[2020-07-28 07:51:49 +0000] [13] [INFO] Booting worker with pid: 13\n",
      "[2020-07-28 07:51:49 +0000] [14] [INFO] Booting worker with pid: 14\n",
      "[2020-07-28 07:51:49,954] WARNING - Using BentoML not from official PyPI release. In order to find the same version of BentoML when deplying your BentoService, you must set the 'core/bentoml_deploy_version' config to a http/git location of your BentoML fork, e.g.: 'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-07-28 07:51:49,974] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.8.3, but loading from BentoML version 0.8.3+42.gb8d36b6\n",
      "[2020-07-28 07:51:49,985] INFO - Micro batch enabled for API `predict`\n",
      "[2020-07-28 07:51:49,985] INFO - Your system nofile limit is 1048576, which means each instance of microbatch service is able to hold this number of connections at same time. You can increase the number of file descriptors for the server process, or launch more microbatch instances to accept more concurrent connection.\n",
      "[2020-07-28 07:51:50,905] WARNING - Using BentoML not from official PyPI release. In order to find the same version of BentoML when deplying your BentoService, you must set the 'core/bentoml_deploy_version' config to a http/git location of your BentoML fork, e.g.: 'bentoml_deploy_version = git+https://github.com/{username}/bentoml.git@{branch}'\n",
      "[2020-07-28 07:51:50,925] WARNING - Saved BentoService bundle version mismatch: loading BentoService bundle create with BentoML version 0.8.3, but loading from BentoML version 0.8.3+42.gb8d36b6\n",
      "2020-07-28 07:51:51.085351: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2020-07-28 07:51:51.085674: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2020-07-28 07:51:52.300840: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2020-07-28 07:51:52.300872: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2020-07-28 07:51:52.300898: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:163] no NVIDIA GPU device is present: /dev/nvidia0 does not exist\n",
      "2020-07-28 07:51:52.301165: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-07-28 07:51:52.325362: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2699905000 Hz\n",
      "2020-07-28 07:51:52.325805: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f10b5e5c00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-07-28 07:51:52.325835: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "^C\n",
      "[2020-07-28 07:51:59 +0000] [1] [INFO] Handling signal: int\n",
      "[2020-07-28 07:51:59 +0000] [13] [INFO] Worker exiting (pid: 13)\n"
     ]
    }
   ],
   "source": [
    "!docker run -p 5000:5000 tensorflow2-fashion-mnist --workers 1 --enable-microbatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy BentoService as REST API server to the cloud\n",
    "\n",
    "\n",
    "BentoML support deployment to multiply cloud provider services, such as AWS Lambda, AWS Sagemaker, Google Cloudrun and etc. You can find the full list and guide on the documentation site at https://docs.bentoml.org/en/latest/deployment/index.html\n",
    "\n",
    "For this demo, we are going to deploy to AWS Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bento_service_tag = f'{bento_svc.name}:{bento_svc.version}'\n",
    "print(bento_service_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml sagemaker deploy first-tf-fashion -b {bento_service_tag} --api-name predict --verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml sagemaker get first-tf-fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws sagemaker-runtime invoke-endpoint --endpoint-name dev-first-tf-fashion --content-type 'application/json' \\\n",
    "--body \"{\\\"instances\\\":[{\\\"b64\\\":\\\"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAA2dJREFUSIntlk9L60oYh59Mp43axJoiVj2KboSuXPoJXLkQ/Fx+Ahe6ceFG3CtdWlFcFf9RKlhFatpSbWuaNLHJnIW3OR7ugcu9BzxccGAgZCbv887v/b1JNKWU4hOH+EzYF/AL+OeBYRjysct83wegUqn8HlApRRRFADw+PrK/v4/jOCQSCTRNi/fpug7AwcHB7wEBhHh/9Pj4mGKxyM7Ozt/2NBoNdnd3MU0zvif/CywMQ6SUnJ+fc3NzQy6Xo1KpsLGxgWVZ9Pt9FhYWaLVadLtd5ubmfiT6b2FRFCGlxHEc9vf3UUrR7/d5fX1FKRXPq6srpJRYlsVgMPhn4LD4URTF12EYxlJubW2Ry+WYnp7G8zz6/T65XC6uYzqdRtd1fN+n2+3iOM6vgcPgw+ILIdA0jTAMSSQSAOzt7WHbNtPT0xiGQbvdJpvNMjU1RTKZJAxD3t7e4ni9Xo/b29tfA4egKIoYDAZxAkPYzs4OpVKJ+fl5Wq0W7XYbz/PIZDK8vr6iaRpjY2Mkk0mUUnG8w8ND4INphjbXNA2lFEKIWD6AWq3GwcEBnuextLSE4zj4vk+r1SKVSqFpGq7rxsnpuo4QgnQ6jRCCYrH4DhxK9TH4MKtms0m1WqVcLvP09EQqlWJ8fJx2u0232+Xt7Q3f9xFCUK1WGQwGTExMkEwmEUKglGJ0dJQwDDEMg8vLS+RQqnq9zv39Pb1ej16vh+d53N3d4bouUkpM0ySKIjqdDp7nIaXEdV1GR0fRdZ0gCJidnaXT6eC6LpZl4TgOLy8vpNNpbNvm+fn5XdJCoUCtVkNKSbPZjA0yBDmOg23bKKXwfR/LsoiiCMdxCMOQdDqNYRhkMhkajUaslGVZCCHwPI8gCJBSIo+Ojtje3iafzzMzMxOfJJVKxe9G0zQJggAhRNxvnuehaRpRFGHbNvV6nevra4IgIAxDAAzDwHVddF3HMAympqaQKysrnJ6ecnFx8aOwf50sm82SzWbJZDIEQYBSilarRblcxnVdut0umqZRKpVYXl5mcXGRQqGA7/uxD6SUfPv2DdM031388SfKcRzOzs4ol8ucnJzQbDZ/atqhA7PZLPl8ntXVVdbW1hgZGYnX19fXeXh4YHJyEtM0MU0TKSW6rrO5ufkz8DPG//sD/AX8I8DvdgnOxdB4B1wAAAAASUVORK5CYII=\\\"}]}\" \\\n",
    "output.json && cat output.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bentoml sagemaker delete first-tf-fashion --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "classification.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "bentoml-dev-py36",
   "language": "python",
   "name": "bentoml-dev-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
